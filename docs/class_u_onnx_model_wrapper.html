<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.2"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>NNEngine: UOnnxModelWrapper Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">NNEngine
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.2 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search",'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('class_u_onnx_model_wrapper.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="class_u_onnx_model_wrapper-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">UOnnxModelWrapper Class Reference</div></div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Inheritance diagram for UOnnxModelWrapper:</div>
<div class="dyncontent">
<div class="center"><img src="class_u_onnx_model_wrapper__inherit__graph.png" border="0" usemap="#a_u_onnx_model_wrapper_inherit__map" alt="Inheritance graph"/></div>
<map name="a_u_onnx_model_wrapper_inherit__map" id="a_u_onnx_model_wrapper_inherit__map">
<area shape="rect" title=" " alt="" coords="5,80,152,107"/>
<area shape="rect" title=" " alt="" coords="44,5,113,32"/>
</map>
<center><span class="legend">[<a target="top" href="graph_legend.html">legend</a>]</span></center></div>
<div class="dynheader">
Collaboration diagram for UOnnxModelWrapper:</div>
<div class="dyncontent">
<div class="center"><img src="class_u_onnx_model_wrapper__coll__graph.png" border="0" usemap="#a_u_onnx_model_wrapper_coll__map" alt="Collaboration graph"/></div>
<map name="a_u_onnx_model_wrapper_coll__map" id="a_u_onnx_model_wrapper_coll__map">
<area shape="rect" title=" " alt="" coords="17,95,164,121"/>
<area shape="rect" title=" " alt="" coords="5,5,75,32"/>
<area shape="rect" href="class_onnx_model.html" title="Manages a ONNX model" alt="" coords="99,5,187,32"/>
</map>
<center><span class="legend">[<a target="top" href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a18c5ea6372d49031b1da63e8161e71b7"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_u_onnx_model_wrapper.html#a18c5ea6372d49031b1da63e8161e71b7">init</a> (const FString &amp;onnxFilePath, const EOnnxProvider onnxProvider, const int gpuDeviceId, const EOnnxGraphOptimizationLevel optimizationLevel=EOnnxGraphOptimizationLevel::Extended)</td></tr>
<tr class="separator:a18c5ea6372d49031b1da63e8161e71b7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a931644a8f8d0352a00a0faeab3f4ca13"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_u_onnx_model_wrapper.html#a931644a8f8d0352a00a0faeab3f4ca13">getInputTensorsInfo</a> (TArray&lt; <a class="el" href="struct_f_onnx_tensor_info.html">FOnnxTensorInfo</a> &gt; &amp;inputTensorsInfo)</td></tr>
<tr class="separator:a931644a8f8d0352a00a0faeab3f4ca13"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9b824227fc1b174238030a869b1a6332"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_u_onnx_model_wrapper.html#a9b824227fc1b174238030a869b1a6332">getOutputTensorsInfo</a> (TArray&lt; <a class="el" href="struct_f_onnx_tensor_info.html">FOnnxTensorInfo</a> &gt; &amp;outputTensorsInfo)</td></tr>
<tr class="separator:a9b824227fc1b174238030a869b1a6332"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a203e2c17a63e4af428661d19c416dc51"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_u_onnx_model_wrapper.html#a203e2c17a63e4af428661d19c416dc51">bindInputByteArray</a> (const <a class="el" href="struct_f_onnx_tensor_info.html">FOnnxTensorInfo</a> &amp;tensorInfo, UPARAM(ref) TArray&lt; uint8 &gt; &amp;dataBuffer)</td></tr>
<tr class="separator:a203e2c17a63e4af428661d19c416dc51"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acc76e7b38acdbba18c0c95ff4eea0e28"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_u_onnx_model_wrapper.html#acc76e7b38acdbba18c0c95ff4eea0e28">bindInputIntArray</a> (const <a class="el" href="struct_f_onnx_tensor_info.html">FOnnxTensorInfo</a> &amp;tensorInfo, UPARAM(ref) TArray&lt; int &gt; &amp;dataBuffer)</td></tr>
<tr class="separator:acc76e7b38acdbba18c0c95ff4eea0e28"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a640ad16a6c5b9bec9935dbd9705784a9"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_u_onnx_model_wrapper.html#a640ad16a6c5b9bec9935dbd9705784a9">bindInputInt64Array</a> (const <a class="el" href="struct_f_onnx_tensor_info.html">FOnnxTensorInfo</a> &amp;tensorInfo, UPARAM(ref) TArray&lt; int64 &gt; &amp;dataBuffer)</td></tr>
<tr class="separator:a640ad16a6c5b9bec9935dbd9705784a9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af3b60caf92c6ebb01e0684619cce796b"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_u_onnx_model_wrapper.html#af3b60caf92c6ebb01e0684619cce796b">bindInputFloatArray</a> (const <a class="el" href="struct_f_onnx_tensor_info.html">FOnnxTensorInfo</a> &amp;tensorInfo, UPARAM(ref) TArray&lt; float &gt; &amp;input)</td></tr>
<tr class="separator:af3b60caf92c6ebb01e0684619cce796b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a21ee4fb11f7a7ed5cd5849c2267f24fb"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_u_onnx_model_wrapper.html#a21ee4fb11f7a7ed5cd5849c2267f24fb">bindOutputByteArray</a> (const <a class="el" href="struct_f_onnx_tensor_info.html">FOnnxTensorInfo</a> &amp;tensorInfo, UPARAM(ref) TArray&lt; uint8 &gt; &amp;dataBuffer)</td></tr>
<tr class="separator:a21ee4fb11f7a7ed5cd5849c2267f24fb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3fd46d1bb10483eded2a354a55f04925"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_u_onnx_model_wrapper.html#a3fd46d1bb10483eded2a354a55f04925">bindOutputIntArray</a> (const <a class="el" href="struct_f_onnx_tensor_info.html">FOnnxTensorInfo</a> &amp;tensorInfo, UPARAM(ref) TArray&lt; int &gt; &amp;dataBuffer)</td></tr>
<tr class="separator:a3fd46d1bb10483eded2a354a55f04925"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a058f76d3a49819977a4be34dc439ad3b"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_u_onnx_model_wrapper.html#a058f76d3a49819977a4be34dc439ad3b">bindOutputInt64Array</a> (const <a class="el" href="struct_f_onnx_tensor_info.html">FOnnxTensorInfo</a> &amp;tensorInfo, UPARAM(ref) TArray&lt; int64 &gt; &amp;dataBuffer)</td></tr>
<tr class="separator:a058f76d3a49819977a4be34dc439ad3b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adf5ba3c8022c987c579f9ab3a723ac23"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_u_onnx_model_wrapper.html#adf5ba3c8022c987c579f9ab3a723ac23">bindOutputFloatArray</a> (const <a class="el" href="struct_f_onnx_tensor_info.html">FOnnxTensorInfo</a> &amp;tensorInfo, UPARAM(ref) TArray&lt; float &gt; &amp;dataBuffer)</td></tr>
<tr class="separator:adf5ba3c8022c987c579f9ab3a723ac23"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abf37a54dcbd573ae85c60e3df19cafb8"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_u_onnx_model_wrapper.html#abf37a54dcbd573ae85c60e3df19cafb8">clearBoundInputs</a> ()</td></tr>
<tr class="separator:abf37a54dcbd573ae85c60e3df19cafb8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4346680518426c2f3efd79057d498c42"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_u_onnx_model_wrapper.html#a4346680518426c2f3efd79057d498c42">clearBoundOutputs</a> ()</td></tr>
<tr class="separator:a4346680518426c2f3efd79057d498c42"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a07eeeea962e22e743d7e22c9067637f3"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_u_onnx_model_wrapper.html#a07eeeea962e22e743d7e22c9067637f3">run</a> ()</td></tr>
<tr class="separator:a07eeeea962e22e743d7e22c9067637f3"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-attribs" name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:a42206f65ebf57356569c1e544a00945f"><td class="memItemLeft" align="right" valign="top"><a id="a42206f65ebf57356569c1e544a00945f" name="a42206f65ebf57356569c1e544a00945f"></a>
<a class="el" href="class_onnx_model.html">OnnxModel</a> *&#160;</td><td class="memItemRight" valign="bottom"><b>onnxModel</b></td></tr>
<tr class="separator:a42206f65ebf57356569c1e544a00945f"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p >Wrapper of <a class="el" href="class_onnx_model.html" title="Manages a ONNX model">OnnxModel</a> to expose functions to Bludprint. </p>
</div><h2 class="groupheader">Member Function Documentation</h2>
<a id="a203e2c17a63e4af428661d19c416dc51" name="a203e2c17a63e4af428661d19c416dc51"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a203e2c17a63e4af428661d19c416dc51">&#9670;&nbsp;</a></span>bindInputByteArray()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void UOnnxModelWrapper::bindInputByteArray </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="struct_f_onnx_tensor_info.html">FOnnxTensorInfo</a> &amp;&#160;</td>
          <td class="paramname"><em>tensorInfo</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">UPARAM(ref) TArray&lt; uint8 &gt; &amp;&#160;</td>
          <td class="paramname"><em>dataBuffer</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p >Specify a pre-allocated data buffer that will be used as the input to this model. The data will be interpreted as a tensor of specified information. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensorInfo</td><td>The information (name, shape, etc.) of the input tensor. For models with fixed shape, just use inputTensorsInfo. For models with dynamic shape, change the values of size and shape in inputTensorsInfo </td></tr>
    <tr><td class="paramname">dataBuffer</td><td>Pointer for the pre-allocated data buffer that will be used as the input to this model </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="af3b60caf92c6ebb01e0684619cce796b" name="af3b60caf92c6ebb01e0684619cce796b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af3b60caf92c6ebb01e0684619cce796b">&#9670;&nbsp;</a></span>bindInputFloatArray()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void UOnnxModelWrapper::bindInputFloatArray </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="struct_f_onnx_tensor_info.html">FOnnxTensorInfo</a> &amp;&#160;</td>
          <td class="paramname"><em>tensorInfo</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">UPARAM(ref) TArray&lt; float &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p >Specify a pre-allocated data buffer that will be used as the input to this model. The data will be interpreted as a tensor of specified information. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensorInfo</td><td>The information (name, shape, etc.) of the input tensor. For models with fixed shape, just use inputTensorsInfo. For models with dynamic shape, change the values of size and shape in inputTensorsInfo </td></tr>
    <tr><td class="paramname">dataBuffer</td><td>Pointer for the pre-allocated data buffer that will be used as the input to this model </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a640ad16a6c5b9bec9935dbd9705784a9" name="a640ad16a6c5b9bec9935dbd9705784a9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a640ad16a6c5b9bec9935dbd9705784a9">&#9670;&nbsp;</a></span>bindInputInt64Array()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void UOnnxModelWrapper::bindInputInt64Array </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="struct_f_onnx_tensor_info.html">FOnnxTensorInfo</a> &amp;&#160;</td>
          <td class="paramname"><em>tensorInfo</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">UPARAM(ref) TArray&lt; int64 &gt; &amp;&#160;</td>
          <td class="paramname"><em>dataBuffer</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p >Specify a pre-allocated data buffer that will be used as the input to this model. The data will be interpreted as a tensor of specified information. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensorInfo</td><td>The information (name, shape, etc.) of the input tensor. For models with fixed shape, just use inputTensorsInfo. For models with dynamic shape, change the values of size and shape in inputTensorsInfo </td></tr>
    <tr><td class="paramname">dataBuffer</td><td>Pointer for the pre-allocated data buffer that will be used as the input to this model </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="acc76e7b38acdbba18c0c95ff4eea0e28" name="acc76e7b38acdbba18c0c95ff4eea0e28"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acc76e7b38acdbba18c0c95ff4eea0e28">&#9670;&nbsp;</a></span>bindInputIntArray()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void UOnnxModelWrapper::bindInputIntArray </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="struct_f_onnx_tensor_info.html">FOnnxTensorInfo</a> &amp;&#160;</td>
          <td class="paramname"><em>tensorInfo</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">UPARAM(ref) TArray&lt; int &gt; &amp;&#160;</td>
          <td class="paramname"><em>dataBuffer</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p >Specify a pre-allocated data buffer that will be used as the input to this model. The data will be interpreted as a tensor of specified information. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensorInfo</td><td>The information (name, shape, etc.) of the input tensor. For models with fixed shape, just use inputTensorsInfo. For models with dynamic shape, change the values of size and shape in inputTensorsInfo </td></tr>
    <tr><td class="paramname">dataBuffer</td><td>Pointer for the pre-allocated data buffer that will be used as the input to this model </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a21ee4fb11f7a7ed5cd5849c2267f24fb" name="a21ee4fb11f7a7ed5cd5849c2267f24fb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a21ee4fb11f7a7ed5cd5849c2267f24fb">&#9670;&nbsp;</a></span>bindOutputByteArray()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void UOnnxModelWrapper::bindOutputByteArray </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="struct_f_onnx_tensor_info.html">FOnnxTensorInfo</a> &amp;&#160;</td>
          <td class="paramname"><em>tensorInfo</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">UPARAM(ref) TArray&lt; uint8 &gt; &amp;&#160;</td>
          <td class="paramname"><em>dataBuffer</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p >Specify a pre-allocated data buffer that will be used for the output from this model. The data will be interpreted as a tensor of specified information. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensorInfo</td><td>The information (name, shape, etc.) of the output tensor. For models with fixed shape, just use outputTensorsInfo. For models with dynamic shape, change the values of size and shape in outputTensorsInfo </td></tr>
    <tr><td class="paramname">dataBuffer</td><td>Pointer for the pre-allocated data buffer that will be used for the output from this model </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="adf5ba3c8022c987c579f9ab3a723ac23" name="adf5ba3c8022c987c579f9ab3a723ac23"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adf5ba3c8022c987c579f9ab3a723ac23">&#9670;&nbsp;</a></span>bindOutputFloatArray()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void UOnnxModelWrapper::bindOutputFloatArray </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="struct_f_onnx_tensor_info.html">FOnnxTensorInfo</a> &amp;&#160;</td>
          <td class="paramname"><em>tensorInfo</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">UPARAM(ref) TArray&lt; float &gt; &amp;&#160;</td>
          <td class="paramname"><em>dataBuffer</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p >Specify a pre-allocated data buffer that will be used for the output from this model. The data will be interpreted as a tensor of specified information. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensorInfo</td><td>The information (name, shape, etc.) of the output tensor. For models with fixed shape, just use outputTensorsInfo. For models with dynamic shape, change the values of size and shape in outputTensorsInfo </td></tr>
    <tr><td class="paramname">dataBuffer</td><td>Pointer for the pre-allocated data buffer that will be used for the output from this model </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a058f76d3a49819977a4be34dc439ad3b" name="a058f76d3a49819977a4be34dc439ad3b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a058f76d3a49819977a4be34dc439ad3b">&#9670;&nbsp;</a></span>bindOutputInt64Array()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void UOnnxModelWrapper::bindOutputInt64Array </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="struct_f_onnx_tensor_info.html">FOnnxTensorInfo</a> &amp;&#160;</td>
          <td class="paramname"><em>tensorInfo</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">UPARAM(ref) TArray&lt; int64 &gt; &amp;&#160;</td>
          <td class="paramname"><em>dataBuffer</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p >Specify a pre-allocated data buffer that will be used for the output from this model. The data will be interpreted as a tensor of specified information. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensorInfo</td><td>The information (name, shape, etc.) of the output tensor. For models with fixed shape, just use outputTensorsInfo. For models with dynamic shape, change the values of size and shape in outputTensorsInfo </td></tr>
    <tr><td class="paramname">dataBuffer</td><td>Pointer for the pre-allocated data buffer that will be used for the output from this model </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a3fd46d1bb10483eded2a354a55f04925" name="a3fd46d1bb10483eded2a354a55f04925"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3fd46d1bb10483eded2a354a55f04925">&#9670;&nbsp;</a></span>bindOutputIntArray()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void UOnnxModelWrapper::bindOutputIntArray </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="struct_f_onnx_tensor_info.html">FOnnxTensorInfo</a> &amp;&#160;</td>
          <td class="paramname"><em>tensorInfo</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">UPARAM(ref) TArray&lt; int &gt; &amp;&#160;</td>
          <td class="paramname"><em>dataBuffer</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p >Specify a pre-allocated data buffer that will be used for the output from this model. The data will be interpreted as a tensor of specified information. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensorInfo</td><td>The information (name, shape, etc.) of the output tensor. For models with fixed shape, just use outputTensorsInfo. For models with dynamic shape, change the values of size and shape in outputTensorsInfo </td></tr>
    <tr><td class="paramname">dataBuffer</td><td>Pointer for the pre-allocated data buffer that will be used for the output from this model </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="abf37a54dcbd573ae85c60e3df19cafb8" name="abf37a54dcbd573ae85c60e3df19cafb8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abf37a54dcbd573ae85c60e3df19cafb8">&#9670;&nbsp;</a></span>clearBoundInputs()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void UOnnxModelWrapper::clearBoundInputs </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p >Clear the boud inputs </p>

</div>
</div>
<a id="a4346680518426c2f3efd79057d498c42" name="a4346680518426c2f3efd79057d498c42"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4346680518426c2f3efd79057d498c42">&#9670;&nbsp;</a></span>clearBoundOutputs()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void UOnnxModelWrapper::clearBoundOutputs </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p >Clear the boud outputs </p>

</div>
</div>
<a id="a931644a8f8d0352a00a0faeab3f4ca13" name="a931644a8f8d0352a00a0faeab3f4ca13"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a931644a8f8d0352a00a0faeab3f4ca13">&#9670;&nbsp;</a></span>getInputTensorsInfo()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void UOnnxModelWrapper::getInputTensorsInfo </td>
          <td>(</td>
          <td class="paramtype">TArray&lt; <a class="el" href="struct_f_onnx_tensor_info.html">FOnnxTensorInfo</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>inputTensorsInfo</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p >Get the name, size, shape, and type of the input tensors of this model </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inputTensorsInfo</td><td>The name, size, shape, and type of the input tensors </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a9b824227fc1b174238030a869b1a6332" name="a9b824227fc1b174238030a869b1a6332"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9b824227fc1b174238030a869b1a6332">&#9670;&nbsp;</a></span>getOutputTensorsInfo()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void UOnnxModelWrapper::getOutputTensorsInfo </td>
          <td>(</td>
          <td class="paramtype">TArray&lt; <a class="el" href="struct_f_onnx_tensor_info.html">FOnnxTensorInfo</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>outputTensorsInfo</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p >Get the name, size, shape, and type of the output tensors of this model </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">outputTensorsInfo</td><td>The name, size, shape, and type of the output tensors </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a18c5ea6372d49031b1da63e8161e71b7" name="a18c5ea6372d49031b1da63e8161e71b7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a18c5ea6372d49031b1da63e8161e71b7">&#9670;&nbsp;</a></span>init()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void UOnnxModelWrapper::init </td>
          <td>(</td>
          <td class="paramtype">const FString &amp;&#160;</td>
          <td class="paramname"><em>onnxFilePath</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const EOnnxProvider&#160;</td>
          <td class="paramname"><em>onnxProvider</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>gpuDeviceId</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const EOnnxGraphOptimizationLevel&#160;</td>
          <td class="paramname"><em>optimizationLevel</em> = <code>EOnnxGraphOptimizationLevel::Extended</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p >Open ONNX model and initialize it. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">onnxFilePath</td><td>Path of the .onnx file </td></tr>
    <tr><td class="paramname">onnxProvider</td><td>Execution provider used for this model </td></tr>
    <tr><td class="paramname">gpuDeviceId</td><td>Which GPU to be used </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a07eeeea962e22e743d7e22c9067637f3" name="a07eeeea962e22e743d7e22c9067637f3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a07eeeea962e22e743d7e22c9067637f3">&#9670;&nbsp;</a></span>run()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void UOnnxModelWrapper::run </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p >Execute the model. Note that you need to bind input and output before calling this method. </p>

</div>
</div>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="class_u_onnx_model_wrapper.html">UOnnxModelWrapper</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.2 </li>
  </ul>
</div>
</body>
</html>
