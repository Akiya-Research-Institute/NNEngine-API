<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.2"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>NNEngine: Manual / マニュアル</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">NNEngine
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.2 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search",'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('index.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">Manual / マニュアル </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p ><a class="anchor" id="mainpage"></a> </p>
<h1><a class="anchor" id="autotoc_md6"></a>
Overview / 概要</h1>
<ul>
<li>A code plugin for <a href="https://www.unrealengine.com/">Unreal Engine 4</a> to use <a href="https://onnx.ai/">ONNX</a> model.</li>
<li>Provides functions for easy and accelerated ML inference callable from BP and C++ using <a href="https://onnxruntime.ai/">ONNX Runtime</a> native library.</li>
<li>Also, provides utility functions such as resizing, cropping, rotating UTexture and converting it to int8 array.</li>
<li><a href="./md_html__demo_project_overview.html">Demo project</a> of human pose estimation and facial capture using a single RGB camera are available.</li>
<li></li>
<li><a href="https://www.unrealengine.com/">Unreal Engine 4</a> で <a href="https://onnx.ai/">ONNX</a> モデルを動かすためのプラグインです。</li>
<li>ブループリントとC++から機械学習推論を簡単・高速実行できる機能を提供します。内部では<a href="https://onnxruntime.ai/">ONNX Runtime</a>ネイティブライブラリを使用しています。</li>
<li>また、UTextureをリサイズ、トリミング、回転したうえでint8配列へ変換する機能等を提供します。</li>
<li>人物姿勢推定と表情のキャプチャを行う<a href="./md_html__demo_project_overview.html">デモプロジェクト</a>も提供されています。</li>
</ul>
<hr  />
<h1><a class="anchor" id="autotoc_md8"></a>
System Requirements / 動作環境</h1>
<ul>
<li>Supported Platform: Windows 10 64bit</li>
<li>Supported UE4 version: 4.26, 4.27</li>
<li>To use GPU acceleration with DirectML, a DirectX 12 capable GPU is required.</li>
<li>To use GPU acceleration with CUDA and TensorRT, a supported NVIDIA GPU is required and the following versions of CUDA, cuDNN, and TensorRT are required to be installed.</li>
<li></li>
<li>対応プラットフォーム：Windows 10 64bit</li>
<li>対応UE4バージョン：4.26, 4.27</li>
<li>DirectMLによるGPUアクセラレーションには、DirectX 12対応GPUが必要です。</li>
<li>TensorRTによるGPUアクセラレーションには、対応するNVIDIA GPUが必要です。また、下記に記載の特定バージョンのCUDA、cuDNN、TensorRTのインストールが必要です。</li>
</ul>
<h3><a class="anchor" id="autotoc_md9"></a>
CUDA, cuDNN, TensorRT versions</h3>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone"></th><th class="markdownTableHeadNone">Other than RTX30** series   </th><th class="markdownTableHeadNone">RTX30** series    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">CUDA   </td><td class="markdownTableBodyNone">11.0.3   </td><td class="markdownTableBodyNone">11.0.3    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">cuDNN   </td><td class="markdownTableBodyNone">v8.0.2 (July 24th, 2020), for CUDA 11.0   </td><td class="markdownTableBodyNone">v8.0.5 (November 9th, 2020), for CUDA 11.0    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">TensorRT   </td><td class="markdownTableBodyNone">7.1.3.4 for CUDA 11.0   </td><td class="markdownTableBodyNone">7.2.2.3 for CUDA 11.0   </td></tr>
</table>
<p >If you are using RTX2080Ti, you might need to use cuDNN v8.0.5. Please try various combinations. <br  />
</p>
<hr  />
<h1><a class="anchor" id="autotoc_md11"></a>
Installation / インストール</h1>
<h2><a class="anchor" id="autotoc_md12"></a>
From UE Marketplace</h2>
<ol type="1">
<li>Purchase at <a href="https://www.unrealengine.com/marketplace/product/74892c770dc149b1b5c4e872804e6ade">https://www.unrealengine.com/marketplace/product/74892c770dc149b1b5c4e872804e6ade</a> and install it.</li>
<li>Create an Unreal Engine project.</li>
<li>Open the project, open "Edit &gt; Plugins" on the editor menu, enable "NNEngine", and restart the project.</li>
</ol>
<ol type="1">
<li><a href="https://www.unrealengine.com/marketplace/product/74892c770dc149b1b5c4e872804e6ade">https://www.unrealengine.com/marketplace/product/74892c770dc149b1b5c4e872804e6ade</a> で購入し、インストールします。</li>
<li>Unreal Engineのプロジェクトを作成します。</li>
<li>プロジェクトを開き、エディタのメニュー上で「編集 &gt; プラグイン」を開き、「NNEngine」を有効にし、プロジェクトを再起動します。</li>
</ol>
<hr  />
<h1><a class="anchor" id="autotoc_md14"></a>
Modules / モジュール構成</h1>
<p >NNEngine consists of the following four modules.</p>
<ol type="1">
<li>OnnxRuntime <br  />
 A module for executing AI using ONNX files. <br  />
 If you just want to use ONNX format AI, you only need this module. <br  />
</li>
<li>TextureProcessing <br  />
 A module for performing image processing on UTexture and creating input data to ONNX. <br  />
 It provides functions such as conversion from UTexture to byte array, scaling, cropping, and rotation. <br  />
</li>
<li>DirectXUtility <br  />
 A module for getting a list of GPUs on a Windows PC. <br  />
 It is used to display a list of GPUs on the end user's PC to let the user to select one. <br  />
</li>
<li>CustomizedOpenCV <br  />
 A module that provides a set of useful functions for image processing. <br  />
 It is used by "2. TextureProcessing" module. <br  />
</li>
</ol>
<p >NNEngineは、下記の4つのモジュールで構成されています。</p>
<ol type="1">
<li>OnnxRuntime <br  />
 ONNXファイルを使ってAIの実行を行うためのモジュール。 <br  />
 単にONNX形式のAIを利用するだけなら、このモジュールだけ使えばOKです。 <br  />
</li>
<li>TextureProcessing <br  />
 UTextureに対して画像処理を行ってONNXへの入力データを作るためのモジュール。 <br  />
 UTextureからバイト配列への変換や、拡縮・切り取り・回転などといった機能を提供します。 <br  />
</li>
<li>DirectXUtility <br  />
 Windows PCのGPUの一覧を取得するためのモジュール。 <br  />
 エンドユーザのPCのGPUの一覧を表示し選択させるといった用途に使います。 <br  />
</li>
<li>CustomizedOpenCV <br  />
 画像処理のための便利な関数群を提供するモジュール。 <br  />
 2のTextureProcessingモジュール内部で利用しています。 <br  />
</li>
</ol>
<p >Overview for the OnnxRuntime and TextureProcessing modules: <br  />
 <img src="images/systemOverview.png" alt="" class="inline"/> <br  />
</p>
<hr  />
<h1><a class="anchor" id="autotoc_md16"></a>
How to use OnnxRuntime module / OnnxRuntimeモジュールの使い方</h1>
<p >This module wraps the ONNX Runtime's C++ API and makes it easy to call from Unreal Engine's Blueprints and C++. <br  />
 An example of use from BP can be found in "Plugins\NNEngine\Content\MinimalExample\MinimalExampleOfOnnxModelWrapper.uasset". <br  />
 (See <a href="./md_html__onnx_introduction.html">Overview of ONNX</a> for the overview of ONNX itself) <br  />
 (See <a href="https://onnxruntime.ai/docs/">the official documentation</a> for how to use ONNX Runtime itself) <br  />
</p>
<p >このモジュールは、ONNX RuntimeのC++ APIをラップし、Unreal EngineのブループリントおよびC++から簡単に呼び出せるようにしたものです。 <br  />
 BPからの使用例は、「Plugins\NNEngine\Content\MinimalExample\MinimalExampleOfOnnxModelWrapper.uasset」にあります。 <br  />
 （ONNX自体の概要は、<a href="./md_html__onnx_introduction.html">ONNXの概要</a>をご覧ください） <br  />
 （ONNX Runtime自体の使い方は、<a href="https://onnxruntime.ai/docs/">公式ドキュメント</a>をご覧ください） <br  />
</p>
<h2><a class="anchor" id="autotoc_md17"></a>
Load ONNX model / ONNXモデルのロード</h2>
<p >Load the AI ​​model saved in ONNX format. <br  />
 NNEngine reads the .onnx file by specifying the path at runtime. <br  />
</p>
<p >ONNX形式で保存されたAIモデルを読み込みます。 <br  />
 NNEngineでは、実行時に.onnxファイルのパスを指定して読み込みを行います。</p>
<h3><a class="anchor" id="autotoc_md18"></a>
BP</h3>
<ol type="1">
<li>Create a Blueprint class and add a variable of <a class="el" href="class_u_onnx_model_wrapper.html">UOnnxModelWrapper</a>.</li>
<li>Construct <a class="el" href="class_u_onnx_model_wrapper.html">UOnnxModelWrapper</a> and call "Init".<ul>
<li>Specify the path to the ONNX model</li>
<li>Specify whether to use CPU or GPU, and which GPU to use.<ul>
<li>To get available GPUs on the system, <a href="#autotoc_md29">call "Get Gpu Info".</a></li>
</ul>
</li>
</ul>
</li>
</ol>
<ol type="1">
<li>ブループリントクラスを新規作成し、UOnnxModelWrapperの変数を追加します。</li>
<li>UOnnxModelWrapperのコンストラクタを呼び出し、次に「Init」ノードを呼び出します。<ul>
<li>このとき、ONNXモデルのパスを指定します。</li>
<li>また、CPUとGPUのどちらを使うか、GPUならどのGPUを使うかを指定します。<ul>
<li>システムで利用可能なGPUの一覧を取得するには、<a href="#autotoc_md29">「Get Gpu Info」を呼び出します。</a></li>
</ul>
</li>
</ul>
</li>
</ol>
<p ><img src="images/OnnxRuntime_load.png" alt="" class="inline"/></p>
<h3><a class="anchor" id="autotoc_md19"></a>
C++</h3>
<ol type="1">
<li>Create a C++ class and add a variable of <a class="el" href="class_onnx_model.html" title="Manages a ONNX model">OnnxModel</a>.</li>
<li>Call the constructor of <a class="el" href="class_onnx_model.html" title="Manages a ONNX model">OnnxModel</a>.<ul>
<li>Specify the path to the ONNX model</li>
<li>Specify whether to use CPU or GPU, and which GPU to use.<ul>
<li>To get available GPUs on the system, call "UDirectXUtilityLibrary::GetGpuInfo()"</li>
</ul>
</li>
</ul>
</li>
</ol>
<ol type="1">
<li>C++クラスを作成し、OnnxModelの変数を追加します。</li>
<li>OnnxModelのコンストラクタを呼び出します。<ul>
<li>このとき、ONNXモデルのパスを指定します。</li>
<li>また、CPUとGPUのどちらを使うか、GPUならどのGPUを使うかを指定します。<ul>
<li>システムで利用可能なGPUの一覧を取得するには、「UDirectXUtilityLibrary::GetGpuInfo()」を呼び出します。</li>
</ul>
</li>
</ul>
</li>
</ol>
<div class="fragment"><div class="line">#pragma once</div>
<div class="line">#include &quot;OnnxModel.h&quot;</div>
<div class="line">#include &quot;OnnxModelMinimumExample.generated.h&quot;</div>
<div class="line"> </div>
<div class="line">UCLASS(Blueprintable, Category = &quot;ONNX Runtime&quot;)</div>
<div class="line">class ONNXRUNTIME_API UOnnxModelMinimumExample : public UObject</div>
<div class="line">{</div>
<div class="line">    GENERATED_BODY()</div>
<div class="line"> </div>
<div class="line">protected:</div>
<div class="line">    OnnxModel* onnxModel;</div>
<div class="line"> </div>
<div class="line">public:</div>
<div class="line">    UOnnxModelMinimumExample()</div>
<div class="line">    {</div>
<div class="line">        onnxModel = new OnnxModel(&quot;Full-path-to-your-AI.onnx&quot;, EOnnxProvider::GPU_DirectML, 0);</div>
<div class="line">    }</div>
<div class="line">};</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md20"></a>
Specify input source / データ入力元の指定</h2>
<h3><a class="anchor" id="autotoc_md21"></a>
BP</h3>
<ol type="1">
<li>Call "Get Input Tensor Info" to confirm the order of the input tensors as well as their types and sizes.</li>
<li>Add variables of byte, integer, integer64, or float arrays whose types and sizes match the previous results.</li>
<li>Call "Bind Input xxx Array" for each input tensor and specify the created array as the data input sources to the ONNX model.</li>
</ol>
<ol type="1">
<li>「Get Input Tensor Info」を呼び出して、入力テンソルの順番、型、サイズを確認します。</li>
<li>上記の型とサイズにあわせて、byte、integer、integer64、floatのいずれかの配列の変数を作成します。</li>
<li>入力テンソルの数だけ「Bind Input xxx Array」を呼び出して、作成した配列をONNXモデルへのデータ入力元として指定します。</li>
</ol>
<p ><img src="images/OnnxRuntime_bindInput.png" alt="" class="inline"/></p>
<h3><a class="anchor" id="autotoc_md22"></a>
C++</h3>
<ol type="1">
<li>Get "inputTensorsInfo" member to confirm the order of the input tensors as well as their types and sizes.</li>
<li>Add variables of arrays whose size in bytes match the previous results.</li>
<li>Call "bindInput" as many as the number of input tensors and specify the created arrays as the data input sources to the ONNX model.</li>
</ol>
<ol type="1">
<li>「OnnxModel::inputTensorsInfo」メンバを参照し、入力テンソルの順番、型、サイズを確認します。</li>
<li>上記の型とサイズにあわせて、byte、integer、integer64、floatのいずれかの配列の変数を作成します。</li>
<li>入力テンソルの数だけ「OnnxModel::bindInput」を呼び出して、作成した配列をONNXモデルへのデータ入力元として指定します。</li>
</ol>
<div class="fragment"><div class="line">TArray&lt;uint8&gt; inputDataBuffer0;</div>
<div class="line">TArray&lt;uint8&gt; inputDataBuffer1;</div>
<div class="line">void setupInputs()</div>
<div class="line">{</div>
<div class="line">    inputDataBuffer0.Init(0, 1 * 256 * 256 * 3);</div>
<div class="line">    inputDataBuffer1.Init(0, 1);</div>
<div class="line">    onnxModel-&gt;bindInput(onnxModel-&gt;inputTensorsInfo[0], inputDataBuffer0.GetData());</div>
<div class="line">    onnxModel-&gt;bindInput(onnxModel-&gt;inputTensorsInfo[1], inputDataBuffer1.GetData());</div>
<div class="line">}</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md23"></a>
Specify output destination / データ出力先の指定</h2>
<h3><a class="anchor" id="autotoc_md24"></a>
BP</h3>
<ol type="1">
<li>Call "Get Output Tensor Info" to confirm the order of the output tensors as well as their types and sizes.</li>
<li>Add variables of byte, integer, integer64, or float arrays whose types and sizes match the previous results.</li>
<li>Call "Bind Output xxx Array" for each output tensor and specify the created array as the data output destination from the ONNX model.</li>
</ol>
<ol type="1">
<li>「Get Output Tensor Info」を呼び出して、出力テンソルの順番、型、サイズを確認します。</li>
<li>上記の型とサイズにあわせて、byte、integer、integer64、floatのいずれかの配列の変数を作成します。</li>
<li>出力テンソルの数だけ「Bind Output xxx Array」を呼び出して、作成した配列をONNXモデルからのデータ出力先として指定します。</li>
</ol>
<p ><img src="images/OnnxRuntime_bindOutput.png" alt="" class="inline"/></p>
<h3><a class="anchor" id="autotoc_md25"></a>
C++</h3>
<ol type="1">
<li>Get "outputTensorsInfo" member to confirm the order of the output tensors as well as their types and sizes.</li>
<li>Add variables of array whose size in bytes match the previous result.</li>
<li>Call "bindOutput" for each output tensor and specify the created array as the data output destination from the ONNX model.</li>
</ol>
<ol type="1">
<li>「OnnxModel::outputTensorsInfo」メンバを参照し、出力テンソルの順番、型、サイズを確認します。</li>
<li>上記の型とサイズにあわせて、byte、integer、integer64、floatのいずれかの配列の変数を作成します。</li>
<li>出力テンソルの数だけ「OnnxModel::bindOutput」を呼び出して、作成した配列をONNXモデルからのデータ出力先として指定します。</li>
</ol>
<div class="fragment"><div class="line">TArray&lt;uint8&gt; outputDataBuffer0;</div>
<div class="line">TArray&lt;uint8&gt; outputDataBuffer1;</div>
<div class="line">void setupOutputs()</div>
<div class="line">{</div>
<div class="line">    outputDataBuffer0.Init(0, 17 * 3);</div>
<div class="line">    outputDataBuffer1.Init(0, 4 * 4);</div>
<div class="line">    onnxModel-&gt;bindOutput(onnxModel-&gt;outputTensorsInfo[0], outputDataBuffer0.GetData());</div>
<div class="line">    onnxModel-&gt;bindOutput(onnxModel-&gt;outputTensorsInfo[1], outputDataBuffer1.GetData());</div>
<div class="line">}</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md26"></a>
Run / 実行</h2>
<ol type="1">
<li>Set data to the array specified as the data input source for the ONNX model.</li>
<li>Call "Run".</li>
<li>Get data from the array specified as the data output destination for the ONNX model.</li>
</ol>
<ol type="1">
<li>ONNXモデルへのデータ入力元として指定した配列に、データをセットします。</li>
<li>「Run」を実行します。</li>
<li>ONNXモデルからのデータ出力先として指定した配列から、結果を取得します。</li>
</ol>
<h3><a class="anchor" id="autotoc_md27"></a>
BP</h3>
<p ><img src="images/OnnxRuntime_run.png" alt="" class="inline"/></p>
<h3><a class="anchor" id="autotoc_md28"></a>
C++</h3>
<div class="fragment"><div class="line">onnxModel-&gt;run();</div>
</div><!-- fragment --> <hr  />
<h1><a class="anchor" id="autotoc_md30"></a>
How to use TextureProcessing / TextureProcessingモジュールの使い方</h1>
<p >Use BP_TextureProcessComponent to precess images. <br  />
 BP_TextureProcessComponent is a component for converting a UTexture image into a byte array of a specified size, as well as scaling, cropping, and rotating the image. <br  />
 The resulting byte array can be used as input data to AI. An example can be found in "Content\NNEngineDemo\MotionCapture_Bp\MotionCapture_BpImplementation.uasset" of the demo project.</p>
<p >BP_TextureProcessComponentを使って、画像処理を行います。 <br  />
 BP_TextureProcessComponentは、UTextureの画像を指定したサイズのバイト配列に変換するためのコンポーネントです。また、その際、画像の拡縮・切り取り・回転を行うことができます。 <br  />
 得られたバイト配列は、OnnxRuntimeモジュールでAIへの入力データとして利用できます。 デモプロジェクトの「Content\NNEngineDemo\MotionCapture_Bp\MotionCapture_BpImplementation.uasset」に使用例があります。</p>
<h2><a class="anchor" id="autotoc_md31"></a>
Create component / Componentの作成</h2>
<ol type="1">
<li>Create a Blueprint class and add BP_TextureProcessComponent.</li>
<li>Specify the image size after image processing as the initial values ​​of Destination Width and Destination Height. <br  />
 This BP_TextureProcessComponent will output the result to a byte array with a size of (Destination Height x Destination Width x 3).</li>
</ol>
<ol type="1">
<li>ブループリントクラスを新規作成し、BP_TextureProcessComponentを追加します。</li>
<li>Destination Width、Destination Heightの初期値に、画像処理後の画像サイズを指定します。 <br  />
 これにより、このBP_TextureProcessComponentでは、（Destination Height × Destination Width × 3）のサイズのバイト配列に結果が出力されるようになります。</li>
</ol>
<p ><img src="images/TextureProcessing_add.png" alt="" class="inline"/></p>
<h2><a class="anchor" id="autotoc_md32"></a>
Simple Scaling / 単純な拡縮</h2>
<p >You can scale an image to the size specified at initialization by calling the "Resize" node of BP_TextureProcessComponent. <br  />
 BP_TextureProcessComponentの「Resize」ノードを呼び出すことで、初期化時に指定したサイズに画像を拡大または縮小することができます。</p>
<p ><img src="images/TextureProcessing_resize.png" alt="" class="inline"/></p>
<h3><a class="anchor" id="autotoc_md33"></a>
Input / 入力</h3>
<ul>
<li>Input texture: Original image. 任意のUTextureを指定します</li>
<li>Do Flip Image: Whether to flip the image during resizing. 画像を左右反転するかどうかを指定します。</li>
<li>Do Rotate Image: Whether to rotate the image during resizing. 画像を90度、180度、270度回転するかどうかを指定します。</li>
</ul>
<h3><a class="anchor" id="autotoc_md34"></a>
Output / 出力</h3>
<ul>
<li>outputHxWxBGR: <br  />
 An array of BGR values of each pixel of the image resized to (Destination Height x Destination Width), while keeping the aspect ratio. If the input and output images have different aspect ratios, part of the output array will be filled with some values. <br  />
 入力画像をアスペクト比を保ったまま（Destination Height × Destination Width）のサイズに拡大または縮小し、各ピクセルのBGR値を並べた（Destination Height × Destination Width × 3）のサイズのバイト配列です。入力と出力の画像のアスペクト比が異なる場合、出力の配列の一部は適当な値で埋められます。</li>
<li>uvScalingFactor: <br  />
 The ratio of the aspect ratios of input and output images. By multiplying the UV coordinates in the output image by this value, you can get the UV coordinates in the input image. For example, if the input image is 16:9 and the output image is square, the uvScalingFactor will be (1, 1.777…). <br  />
 入力画像と出力画像のアスペクト比の比です。出力画像でのUV座標にこの値を掛けることで、入力画像でのUV座標を得ることができます。例えば、入力画像が16:9で出力画像が正方形だった場合、uvScalingFactorは (1, 1.777…) となります。</li>
</ul>
<h2><a class="anchor" id="autotoc_md35"></a>
Affine transform / アフィン変換</h2>
<p >By calling the "Affine Transform" node of BP_TextureProcessComponent, you can transform the input image and then scale it to the size specified at initialization. <br  />
 See a linear algebra textbook for affine transformation itself.</p>
<p >BP_TextureProcessComponentの「Affine Transform」ノードを呼び出すことで、入力画像をAffine変換した上で、初期化時に指定したサイズに画像を拡大または縮小することができます。 <br  />
 Affine変換自体については、適当な線形代数の教科書を参照してください。</p>
<p ><img src="images/TextureProcessing_affine.png" alt="" class="inline"/></p>
<h3><a class="anchor" id="autotoc_md36"></a>
Input / 入力</h3>
<ul>
<li>Input texture: Original image. 任意のUTextureを指定します</li>
<li>Inverse Normalized Affine Mat: <br  />
 Specifies the inverse of the matrix which represents the affine transformation when the input / output image size is (1, 1). This is equal to the matrix which represents the affine transformation in UV coordinates. <br  />
 入出力の画像サイズを(1, 1)としたときのAffine変換の逆行列を指定します。これはすなわち、UV座標でのAffine変換行列です。</li>
<li>Do Flip Image: Whether to flip the image during resizing. 画像を左右反転するかどうかを指定します。</li>
<li>Do Rotate Image: Whether to rotate the image during resizing. 画像を90度、180度、270度回転するかどうかを指定します。</li>
</ul>
<h3><a class="anchor" id="autotoc_md37"></a>
Output / 出力</h3>
<ul>
<li>outputHxWxBGR: <br  />
 An array of BGR values of each pixel of the image after transformation and resizing to (Destination Height x Destination Width). <br  />
 Affine変換後の画像を（Destination Height × Destination Width）のサイズに拡大または縮小し、各ピクセルのBGR値を並べた（Destination Height × Destination Width × 3）のサイズのバイト配列です。</li>
</ul>
<h2><a class="anchor" id="autotoc_md38"></a>
Function to find the Affine transformation matrix 1 / Affine変換行列を求める関数1</h2>
<p >By calling the "Get Inverse Affine Mat" node, you can find the inverse matrix of the matrix that represents the affine transformation that crops an image to an arbitrary square area. <br  />
 「Get Inverse Affine Mat」ノードを呼び出すことで、画像を任意の正方形の領域にトリミングするアフィン変換を表す行列の逆行列を取得することができます。</p>
<p ><img src="images/TextureProcessing_getAffine1.png" alt="" class="inline"/></p>
<h3><a class="anchor" id="autotoc_md39"></a>
Input / 入力</h3>
<ul>
<li>Center: The center of the square area in the coordinate of the input image. 切り出す正方形領域の中心を、入力画像の座標系で表した値</li>
<li>Orientation: The orientation of the Y-axis of the square area in the coordinate of the input image. For example, (0, 1) when there is no rotation, and (-1, 0) when rotating 90 degrees clockwise. <br  />
 切り出す正方形領域のY軸の向きを、入力画像の座標系で表した値。例えば、回転なしの場合は(0, 1)、時計回りに90度回転する場合は(-1, 0)とする。</li>
<li>Size: The length of the side of the square area in the coordinate of the input image. 切り出す正方形領域の辺の長さを、入力画像の座標系で表した値</li>
</ul>
<h3><a class="anchor" id="autotoc_md40"></a>
Output / 出力</h3>
<ul>
<li>Out Inverse Affine Mat: Inverse matrix of the matrix representing the obtained affine transformation 求めたAffine変換を表す行列の逆行列</li>
</ul>
<h2><a class="anchor" id="autotoc_md41"></a>
Function to find the Affine transformation matrix 2 / Affine変換行列を求める関数2</h2>
<p >By calling the "Get Inverse Affine Mat From 2 Points" node, you can find the inverse matrix of the matrix that represents the affine transformation that crops an image to an arbitrary square area. <br  />
 「Get Inverse Affine Mat」ノードを呼び出すことで、画像を任意の正方形の領域にトリミングするアフィン変換を表す行列の逆行列を取得することができます。</p>
<p ><img src="images/TextureProcessing_getAffine2.png" alt="" class="inline"/></p>
<h3><a class="anchor" id="autotoc_md42"></a>
Input / 入力</h3>
<ul>
<li>Center: The center of the square area in the coordinate of the input image. 切り出す正方形領域の中心を、入力画像の座標系で表した値</li>
<li>Top Center: The center of the top edge of the square area in the coordinate of the input image. 切り出す正方形領域の上端の中心を、入力画像の座標系で表した値</li>
<li>Scaling Factor: <br  />
 Parameter for adjusting the size of the square area. The side of the square area will be (The distance between Center and Top Center * 2 * this value). <br  />
 切り出す正方形領域の大きさ調整のパラメータ。(CenterとTop Centerの距離 × 2 × この値)が正方形領域の辺の長さとなる。</li>
</ul>
<h3><a class="anchor" id="autotoc_md43"></a>
Output / 出力</h3>
<ul>
<li>Out Inverse Affine Mat: Inverse matrix of the matrix representing the obtained affine transformation 求めたAffine変換を表す行列の逆行列</li>
</ul>
<hr  />
<h1><a class="anchor" id="autotoc_md45"></a>
How to use DirectXUtility module / DirectXUtilityモジュールの使い方</h1>
<p >An example can be found in "Content\NNEngineDemo\Common\WidgetToChangeCpuGpu.uasset" of the demo project. <br  />
 デモプロジェクトの「Content\NNEngineDemo\Common\WidgetToChangeCpuGpu.uasset」に例があります。</p>
<ol type="1">
<li>Call the "Get Gpu Info" node to get an array of Gpu Info structures, which is a list of GPUs available on your PC.</li>
<li>You can get the device ID and name from the Gpu Info structure.</li>
<li>You can specify which GPU to use by specifying this device ID when initializing the <a class="el" href="class_u_onnx_model_wrapper.html">UOnnxModelWrapper</a> or <a class="el" href="class_onnx_model.html" title="Manages a ONNX model">OnnxModel</a>.</li>
</ol>
<ol type="1">
<li>「Get Gpu Info」ノードを呼び出すと、PCで利用可能なGPUのリストであるGpu Info構造体の配列が取得できます。</li>
<li>Gpu Info構造体から、デバイスIDと名前が取得できます。</li>
<li>このデバイスIDをUOnnxModelWrapperまたはOnnxModelの初期化時に指定することで、使用するGPUを指定できます。</li>
</ol>
<p ><img src="images/GetGpuInfo.png" alt="Get GPU Info" class="inline"/></p>
<hr  />
<h1><a class="anchor" id="autotoc_md47"></a>
How to use CustomizedOpenCV module / CustomizedOpenCVモジュールの使い方</h1>
<p >Based on OpenCV 4.4.0 (OpenCV 4.5.4 for Android), some functions are disabled so that it can be built with Unreal Engine. <br  />
 It can be used in C++ by including the OpenCV header as shown below. <br  />
</p>
<p >OpenCV 4.4.0 (Android向けにはOpenCV 4.5.4) をベースに、Unreal Engineでビルドできるよう一部の関数を無効にしたものです。 <br  />
 C++で、下記のようにOpenCVのヘッダをインクルードすることで利用できます。</p>
<div class="fragment"><div class="line">##undef check // the check macro causes problems with opencv headers</div>
<div class="line">##include &quot;opencv2/core/core.hpp&quot;</div>
</div><!-- fragment --><p >Note that this module is created only for use from the TextureProcessing module, and not all OpenCV functions can be used. <br  />
 See <a href="https://opencv.org/">the official documentation</a> for how to use OpenCV itself. <br  />
</p>
<p >なお、あくまでTextureProcessingモジュールからの利用のために作成されたモジュールであり、OpenCVの全ての機能が利用可能なわけではありません。 <br  />
 OpenCV自体の使い方は、<a href="https://opencv.org/">公式ドキュメント</a>をご覧ください。</p>
<hr  />
<h1><a class="anchor" id="autotoc_md49"></a>
Build / ビルド</h1>
<h2><a class="anchor" id="autotoc_md50"></a>
Build without CUDA and TensorRT / CUDAとTensorRTを除外してビルドする</h2>
<p >This plugin contains a large (162MB) DLL, "onnxruntime_providers_cuda.dll". You may want to exclude it to reduce packaged game size. <br  />
 To do that, you need to disable CUDA and TensorRT <a href="https://onnxruntime.ai/docs/execution-providers/">execution providers</a> by following the steps below:</p>
<ul>
<li>Open "(Your installation path of UE4)/Engine/Plugins/Marketplace/NNEngine/Source/OnnxRuntime/OnnxRuntime.Build.cs"</li>
<li><p class="startli">Change line 20 and 21 as follows:</p>
<p class="startli">Before </p><pre class="fragment">  bool doUseCuda = true;
  bool doUseTensorRT = true;
</pre><p> After </p><pre class="fragment">  bool doUseCuda = false;
  bool doUseTensorRT = false;
</pre></li>
<li>Build the project.</li>
</ul>
<p >このプラグインには、大きなサイズ（162MB）のDLL「onnxruntime_providers_cuda.dll」が含まれています。パッケージ化したゲームのサイズを小さくするために、これを除外したくなるかもしれません。 その場合、下記手順にしたがって、CUDA および TensorRT の <a href="https://onnxruntime.ai/docs/execution-providers/">execution provider</a> を無効にする必要があります。</p>
<ul>
<li>"(UE4インストールパス)/Engine/Plugins/Marketplace/NNEngine/Source/OnnxRuntime/OnnxRuntime.Build.cs"を開きます。</li>
<li><p class="startli">20行目と21行目を下記の通り変更します。</p>
<p class="startli">変更前 </p><pre class="fragment">  bool doUseCuda = true;
  bool doUseTensorRT = true;
</pre><p> 変更後 </p><pre class="fragment">  bool doUseCuda = false;
  bool doUseTensorRT = false;
</pre></li>
<li>プロジェクトをビルドします。</li>
</ul>
<hr  />
<h1><a class="anchor" id="autotoc_md52"></a>
Changelog / 更新履歴</h1>
<ul>
<li>v1.0 (2021-12-21)<ul>
<li>First release. </li>
</ul>
</li>
</ul>
</div></div><!-- PageDoc -->
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.2 </li>
  </ul>
</div>
</body>
</html>
